{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import csv\n",
    "import datetime\n",
    "from urllib.request import urlopen\n",
    "\n",
    "today = datetime.datetime.today()\n",
    "\n",
    "# Show all data \n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "\n",
    "# Read the information in 'committee-info.json' which contains information such as roste_count, description, established, roster, etc.\n",
    "# The 'committee-info.json' was downloaded from 'https://whimsy.apache.org/public/'\n",
    "# committees_json = open('committee-info.json').read()\n",
    "\n",
    "# or get data directly from 'https://whimsy.apache.org/public/committee-info.json'\n",
    "url = 'https://whimsy.apache.org/public/committee-info.json'\n",
    "response = urlopen(url) \n",
    "committees_json = response.read()\n",
    "committees_info = json.loads(committees_json) \n",
    "committees = committees_info['committees']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Create a datafame, which contains the members' information for each committee: committee name, name, id, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "committer = pd.DataFrame()\n",
    "\n",
    "for item in committees:\n",
    "    committee_info = pd.DataFrame.from_dict(committees[item]['roster'],orient='index',columns=['name','date'])\n",
    "    committee_info['committee'] = item\n",
    "    committee_info['description'] = committees[item]['description']\n",
    "\n",
    "    committer = pd.concat([committer,committee_info],axis = 0)\n",
    "\n",
    "committer['date'] = pd.to_datetime(committer['date'])\n",
    "committer['year'] = committer['date'].dt.year\n",
    "committer['month'] = committer['date'].dt.month\n",
    "committeeList = list(set(committer['committee']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeYearColumn(df):\n",
    "    # Complete the year from the year the project was created up to this year\n",
    "    year_list = df['year']\n",
    "    year_list_new = list(range(year_list.min(),today.year + 1))\n",
    "    add_list = []\n",
    "    for y in year_list_new:\n",
    "        new_list = list(df[df['year'] == y]['new'])\n",
    "        if len(new_list) > 0:\n",
    "            add_list.append(new_list[0])\n",
    "        else:\n",
    "            add_list.append(0)\n",
    "\n",
    "    new_df = pd.DataFrame(columns=['year','new','committee'])\n",
    "    new_df['year'] = year_list_new\n",
    "    new_df['new'] = add_list\n",
    "    new_df['committee'] = list(df['committee'])[0]\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def addTotalColumn(df):\n",
    "    # Input a dataframe, output a dataframe with a total column\n",
    "    # df columns:committee, year,new\n",
    "    dataframe = df\n",
    "    year_list = df['year']\n",
    "    dataframe['total'] = [df[df['year'] <= y]['new'].sum() for y in year_list]\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def dataframeToList(df):\n",
    "    # convert the array to a list\n",
    "    new_list = [list(df.columns)] +  np.array(df).tolist()\n",
    "    return new_list\n",
    "\n",
    "\n",
    "def groupByYear(raw_df):\n",
    "    # Divide into smaller dataframes by year, then sort by total and convert to a new array\n",
    "    # '2019':xaixs:[],value:[]\n",
    "    yearList = list(set(raw_df['year']))\n",
    "    dic = {}\n",
    "    for year in yearList:\n",
    "        dic[year]={}\n",
    "        df = raw_df[raw_df['year'] == year]\n",
    "        dic[year]['yAxis'] = list(df['committee'])\n",
    "        dic[year]['value'] = list(df['total'])\n",
    "    return dic\n",
    "    # return new_df\n",
    "\n",
    "\n",
    "def BoxplotData(raw_df):\n",
    "    # group the dataframe by committee, year and form a new dataframe\n",
    "    df = raw_df.groupby(['committee','year'])['name'].count().to_frame()\n",
    "    df.reset_index(inplace=True) \n",
    "    df.rename(columns={'name':'new'},inplace=True)\n",
    "    # then merge\n",
    "    result_df = pd.DataFrame()\n",
    "    for committee_name in list(set(df['committee'])):\n",
    "        # split the dataframe into sub-dataframes divided by committee\n",
    "        sub_df = df[df['committee'] == committee_name]\n",
    "        # Add the missing years\n",
    "        sub_df = completeYearColumn(sub_df)\n",
    "        # Add a total column\n",
    "        sub_df = addTotalColumn(sub_df)\n",
    "        # Merge them to target dataframe\n",
    "        result_df = pd.concat([result_df,sub_df],axis=0,ignore_index=True)\n",
    "\n",
    "    result_dict = groupByYear(result_df)\n",
    "\n",
    "    # turn the dataframe to a list\n",
    "    data_list = dataframeToList(result_df)\n",
    "\n",
    "    return data_list, result_dict\n",
    "\n",
    "boxplot, bar = BoxplotData(committer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summarise the committee information, including the year the committee was created, description, name, total number of people to date, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import NA\n",
    "\n",
    "# Extracts the creation time of the committee  e.g. \"12/2000, reestablished 10/2002\" => 12/2000\n",
    "def extractDate(x):\n",
    "    if x:\n",
    "        return x.replace(',',';').split(';')[0]\n",
    "    else:\n",
    "        return NA\n",
    "\n",
    "committees = pd.DataFrame.from_dict(committees,orient='index',columns=[ \"display_name\",\"established\",\"roster_count\"])\n",
    "committees['established'] = pd.to_datetime(committees['established'].map(extractDate))\n",
    "committees['description'] = [committees_info['committees'][index]['description'] for index in committees.index]\n",
    "committees.reset_index(inplace=True)\n",
    "committees.rename(columns={'index':'committee_name'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data to graph the annual growth in committee size: yaxis, xaixs, value=[[x1,y1,size1],[x1,y2,size2]]\n",
    "\n",
    "Since the total number of committees was too large for the graph to display, the data was filtered， removed the committees with the maximum annual growth of less than 15 from the display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the year and committee columns to create a new column for easy grouping of data\n",
    "\n",
    "\n",
    "from unittest import result\n",
    "\n",
    "\n",
    "def dataFilter(raw_df):\n",
    "    \n",
    "    committee_list = raw_df['committee']\n",
    "    drop_list = []\n",
    "    for committee_name in committee_list:\n",
    "        sub_df = raw_df[raw_df['committee'] == committee_name] \n",
    "        if sub_df['size'].max() < 15:\n",
    "            drop_list.append(committee_name)\n",
    "            index = raw_df[raw_df['committee'] == committee_name].index[0]\n",
    "            raw_df = raw_df.drop(index=index)\n",
    "    return raw_df\n",
    "\n",
    "def chartData(raw_df):\n",
    "\n",
    "    yAxis_value = list(set(raw_df['committee']))\n",
    "    xAxis_value = list(set(raw_df['year']))\n",
    "    xAxis_value.sort()\n",
    "    size_value = []\n",
    "    for index, row in raw_df.iterrows():\n",
    "        size_value.append([yAxis_value.index(row['committee']),xAxis_value.index(row['year']),row['size']])\n",
    "    \n",
    "    return {\n",
    "        'yAxis':yAxis_value,\n",
    "        'xAxis':xAxis_value,\n",
    "        'size':size_value\n",
    "    }\n",
    "\n",
    "def getTag(str):\n",
    "    if pd.isna(str) == False:\n",
    "        return str[0].upper()\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def addTag(raw_df):\n",
    "    df = raw_df\n",
    "    df['tag'] = df['committee'].apply(getTag)\n",
    "    return df\n",
    "\n",
    "def getData(raw_df):\n",
    "    df = raw_df.groupby(['committee','year'])['name'].count().to_frame()\n",
    "    df.reset_index(inplace=True) #turn the grouped indexes into columns\n",
    "    df.rename(columns={'name':'size'},inplace=True)\n",
    "    result_df = chartData(df)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def ScatterData(raw_df):\n",
    "    df = addTag(raw_df)\n",
    "    tag_list = list(set(df['tag']))\n",
    "    result = {}\n",
    "    for tag in tag_list:\n",
    "        sub_df = df[df['tag'] == tag]\n",
    "        sub_dict = getData(sub_df)\n",
    "        result[tag] = sub_dict\n",
    "    return result\n",
    "        \n",
    "    \n",
    "scatter = ScatterData(committer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subchart: monthly growth graph for the selected committee "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def completeMonthColumn(df):\n",
    "    # Complete the year-months from the date of creation to the present\n",
    "    df['year_month'] = df['year'].map(str) +'-' +df['month'].map(str)\n",
    "    result_dict = {}\n",
    "\n",
    "    for committee in committeeList:\n",
    "        sub_df = df[df['committee'] == committee]\n",
    "        year_list = sub_df['year']\n",
    "        date_list = list(sub_df['year_month'])\n",
    "        date_list_new = [str(year) + '-' + str(month) for year in range(int(year_list.min()),today.year + 1) for month in range(1,13)]\n",
    "        add_list =[]\n",
    "        for date in date_list_new:\n",
    "            if date in date_list:\n",
    "                add_list.append(list(sub_df[sub_df['year_month'] == date]['add'])[0])\n",
    "            else:\n",
    "                add_list.append(0)\n",
    "        result_dict[committee] = {\n",
    "            'xAxis':date_list_new,\n",
    "            'values':add_list,\n",
    "            'description':committees_info['committees'][committee][\"description\"],\n",
    "            'established':committees_info['committees'][committee][\"established\"]\n",
    "        }\n",
    "        \n",
    "\n",
    "    return result_dict\n",
    "            \n",
    "def lineData(raw_df):\n",
    "    df = raw_df.groupby(['committee','year','month'])['name'].count().to_frame()\n",
    "    df.reset_index(inplace = True)\n",
    "    df.rename(columns={'name':'add'},inplace=True)\n",
    "    result_dict = completeMonthColumn(df)\n",
    "    return result_dict\n",
    "    \n",
    "\n",
    "committee_detail_dict = lineData(committer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取podlings数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "podlings_url = 'https://whimsy.apache.org/public/public_podlings.json'\n",
    "response = urlopen(podlings_url) \n",
    "podlings_json = response.read()\n",
    "podlings_info = json.loads(podlings_json) \n",
    "Podlings = podlings_info['podling']\n",
    "# 可以输出至json文件中用于查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "podlings = pd.DataFrame()\n",
    "\n",
    "def getY_M(date_str):\n",
    "    if pd.isna(date_str) == False:\n",
    "        year = date_str.split('-')[0]\n",
    "        month = date_str.split('-')[1]\n",
    "        return '-'.join([year,month])\n",
    "    else:\n",
    "        return str(today.year)+'-'+ str(today.month) + '-' + str(today.day)\n",
    "\n",
    "\n",
    "podlings_status_info = pd.DataFrame.from_dict(Podlings,orient='index')[['name','status','startdate','enddate']]\n",
    "podlings_status_info['startmonth'] = pd.to_datetime(podlings_status_info['startdate'].map(getY_M))\n",
    "podlings_status_info['endmonth'] = pd.to_datetime(podlings_status_info['enddate'].map(getY_M))\n",
    "podlings_dateList = [str(year) + '-' + str(month) for year in range(int(podlings_status_info['startmonth'].min().year),today.year + 1) for month in range(1,13)]\n",
    "Podlings_yearList = [str(year) for year in range(int(podlings_status_info['startmonth'].min().year),today.year + 1)]\n",
    "\n",
    "\n",
    "\n",
    "# dataMin = podlings_status_info['startdate'].min().strftime('%Y-%m')\n",
    "# dateList=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getCurrent(date_str,raw_df):\n",
    "#     year = date_str.split('-')[0]\n",
    "#     month = date_str.split('-')[1]\n",
    "#     df = raw_df[(raw_df['startmonth'].dt.date <= datetime.date(int(year),int(month),1)) & (raw_df['endmonth'].dt.date >= datetime.date(int(year),int(month),1))]\n",
    "#     return df.count()['name'].item()\n",
    "\n",
    "# def getGraduated(date_str,raw_df):\n",
    "#     year = date_str.split('-')[0]\n",
    "#     month = date_str.split('-')[1]\n",
    "#     df = raw_df[(raw_df['status'] == 'graduated') & (raw_df['endmonth'].dt.date <= datetime.date(int(year),int(month),1))]\n",
    "#     return - df.count()['name'].item()\n",
    "\n",
    "# def getRetired(date_str,raw_df):\n",
    "#     year = date_str.split('-')[0]\n",
    "#     month = date_str.split('-')[1]\n",
    "#     df = raw_df[(raw_df['status'] == 'retired') & (raw_df['endmonth'].dt.date <= datetime.date(int(year),int(month),1))]\n",
    "#     return - df.count()['name'].item()\n",
    "\n",
    "# def status(date_str,raw_df):\n",
    "#     year = date_str.split('-')[0]\n",
    "#     month = date_str.split('-')[1]\n",
    "#     return {\n",
    "#         'new':list(raw_df[raw_df['startmonth'].dt.date == datetime.date(int(year),int(month),1)]['name']),\n",
    "#         'graduate':list(raw_df[(raw_df['status'] == 'graduated') & (raw_df['endmonth'].dt.date == datetime.date(int(year),int(month),1))]['name']),\n",
    "#         'retire':list(raw_df[(raw_df['status'] == 'retired') & (raw_df['endmonth'].dt.date == datetime.date(int(year),int(month),1))]['name'])\n",
    "#     }\n",
    "# def BarData_DATE():\n",
    "#     BarData={}\n",
    "#     BarData['dateList'] = podlings_dateList\n",
    "#     BarData['current'] =[]\n",
    "#     BarData['graduated'] = []\n",
    "#     BarData['retired'] = []\n",
    "#     BarData['status']={}\n",
    "#     for date in podlings_dateList:\n",
    "#         BarData['current'].append(getCurrent(date,podlings_status_info))\n",
    "#         BarData['graduated'].append(getGraduated(date,podlings_status_info))\n",
    "#         BarData['retired'].append(getRetired(date,podlings_status_info))\n",
    "#         BarData['status'][date] = status(date,podlings_status_info)\n",
    "#     return BarData\n",
    "\n",
    "# BarData_DATE = BarData_DATE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yearList': ['2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022'], 'new': [14, 16, 18, 20, 11, 19, 14, 22, 27, 14, 23, 19, 30, 30, 15, 14, 11, 9, 5, 4], 'graduated': [-1, -9, -11, -6, -17, -7, -7, -12, -6, -33, -20, -17, -12, -12, -19, -9, -12, -9, -6, -4], 'retired': [0, -1, -1, -5, -7, -2, -3, -2, -5, -7, -1, -2, -6, -2, -6, -9, -3, -5, -2, -2], 'status': {'2003': {'new': ['AltRMI', 'Axion', 'Depot', 'Directory', 'FtpServer', 'Geronimo', 'JaxMe', 'jUDDI', 'Lenya', 'Pluto', 'SpamAssassin', 'Tapestry', 'WSRP4J', 'XMLBeans'], 'graduated': ['Tapestry'], 'retired': []}, '2004': {'new': ['Agila', 'Apollo', 'Beehive', 'Derby', 'Graffito', 'Hermes', 'httpd-CLI', 'iBATIS', 'Jackrabbit', 'JuiCE', 'log4cxx', 'log4net', 'Log4php', 'MerlinDeveloper', 'Muse', 'MyFaces'], 'graduated': ['Geronimo', 'httpd-CLI', 'JaxMe', 'jUDDI', 'Lenya', 'MerlinDeveloper', 'Pluto', 'SpamAssassin', 'XMLBeans'], 'retired': ['Depot']}, '2005': {'new': ['ActiveMQ', 'Felix', 'Harmony', 'Heraldry', 'JDO', 'Lucene4c', 'mod_ftp', 'Nutch', 'Roller', 'ServiceMix', 'stdcxx', 'Synapse', 'Tobago', 'TSIK', 'Tuscany', 'WADI', 'Woden', 'XMLBeans/C++'], 'graduated': ['Apollo', 'Beehive', 'Derby', 'Directory', 'Hermes', 'iBATIS', 'JDO', 'log4cxx', 'Muse', 'MyFaces', 'Nutch'], 'retired': ['WADI']}, '2006': {'new': ['Abdera', 'Cayenne', 'CXF', 'Ivy', 'Kabuki', 'Lokahi', 'NMaven', 'Ode', 'OFBiz', 'OpenEJB', 'OpenJPA', 'Qpid', 'River', 'Solr', 'Trinidad', 'UIMA', 'WebWork 2', 'Wicket', 'XAP', 'Yoko'], 'graduated': ['Cayenne', 'Harmony', 'Jackrabbit', 'OFBiz', 'Tobago', 'WebWork 2'], 'retired': ['Agila', 'Axion', 'Kabuki', 'Lucene4c', 'TSIK']}, '2007': {'new': ['Buildr', 'Composer', 'Imperius', 'JSPWiki', 'Pig', 'RCF', 'Sanselan', 'Shindig', 'Sling', 'Tika', 'TripleSoup'], 'graduated': ['ActiveMQ', 'Felix', 'FtpServer', 'Ivy', 'log4net', 'mod_ftp', 'Ode', 'OpenEJB', 'OpenJPA', 'Roller', 'ServiceMix', 'Solr', 'stdcxx', 'Synapse', 'Trinidad', 'Wicket', 'Woden'], 'retired': ['AltRMI', 'Graffito', 'Heraldry', 'JuiCE', 'TripleSoup', 'XMLBeans/C++', 'Yoko']}, '2008': {'new': ['Bluesky', 'Click', 'CouchDB', 'Droids', 'Empire-db', 'ESME', 'Etch', 'Hama', 'Kato', 'Olio', 'OpenWebBeans', 'PDFBox', 'PhotArk', 'RAT', 'Shiro', 'Stonehenge', 'Tashi', 'Thrift', 'VCL'], 'graduated': ['Abdera', 'CouchDB', 'CXF', 'Pig', 'Qpid', 'Tika', 'Tuscany'], 'retired': ['Composer', 'NMaven']}, '2009': {'new': ['ACE', 'Aries', 'Cassandra', 'Chemistry', 'Clerezza', 'HISE', 'Libcloud', 'Pivot', 'SocialSite', 'Subversion', 'Traffic Server', 'VXQuery', 'Wink', 'Wookie'], 'graduated': ['Buildr', 'Click', 'OpenWebBeans', 'PDFBox', 'Pivot', 'Sanselan', 'Sling'], 'retired': ['Lokahi', 'RCF', 'XAP']}, '2010': {'new': ['Alois', 'Amber', 'Bean Validation', 'Celix', 'Chukwa', 'Deltacloud', 'Gora', 'Isis', 'Jena', 'Kitty', 'Lucy', 'ManifoldCF', 'Mesos', 'NPanday', 'Nuvem', 'OODT', 'OpenNLP', 'SIS', 'Stanbol', 'Wave', 'Whirr', 'Zeta Components'], 'graduated': ['Aries', 'Cassandra', 'Chemistry', 'ESME', 'Log4php', 'OODT', 'Shindig', 'Shiro', 'Subversion', 'Thrift', 'Traffic Server', 'UIMA'], 'retired': ['SocialSite', 'WSRP4J']}, '2011': {'new': ['Accumulo', 'Airavata', 'Ambari', 'Any23', 'AWF', 'Bigtop', 'Bloodhound', 'Cordova', 'DeltaSpike', 'DirectMemory', 'EasyAnt', 'Flex', 'Flume', 'Giraph', 'HCatalog', 'Kafka', 'Kalumet', 'Lucene.NET', 'MRUnit', 'ODF Toolkit', 'OGNL', 'Oozie', 'Openmeetings', 'OpenOffice.org', 'Rave', 'S4', 'Sqoop'], 'graduated': ['ACE', 'Deltacloud', 'Libcloud', 'OGNL', 'River', 'Whirr'], 'retired': ['Alois', 'Bluesky', 'Imperius', 'Olio', 'Stonehenge']}, '2012': {'new': ['Allura', 'Blur', 'CloudStack', 'Crunch', 'cTAKES', 'DeviceMap', 'Drill', 'Hadoop Development Tools (HDT)', 'Helix', 'Marmotta', 'Onami', 'Ripple', 'Streams', 'Syncope'], 'graduated': ['Accumulo', 'Airavata', 'Any23', 'Bean Validation', 'Bigtop', 'Cordova', 'DirectMemory', 'Empire-db', 'Flex', 'Flume', 'Giraph', 'Gora', 'Hama', 'Isis', 'Jena', 'Kafka', 'Lucene.NET', 'Lucy', 'ManifoldCF', 'MRUnit', 'Nuvem', 'Oozie', 'OpenNLP', 'OpenOffice.org', 'RAT', 'Rave', 'SIS', 'Sqoop', 'Stanbol', 'Syncope', 'VCL', 'Wink', 'Wookie'], 'retired': ['AWF', 'HISE', 'Kato', 'Kitty', 'PhotArk', 'Tashi', 'Zeta Components']}, '2013': {'new': ['Aurora', 'BatchEE', 'Curator', 'Falcon', 'jclouds', 'Knox', 'log4cxx2', 'MetaModel', 'MRQL', 'Olingo', 'Open Climate Workbench', 'Phoenix', 'Provisionr', 'Samza', 'Sentry', 'Spark', 'Sirona', 'Storm', 'Stratos', 'Tajo', 'Tez', 'Twill', 'Usergrid'], 'graduated': ['Ambari', 'Amber', 'Bloodhound', 'Chukwa', 'Clerezza', 'CloudStack', 'Crunch', 'cTAKES', 'Curator', 'DeltaSpike', 'EasyAnt', 'Etch', 'HCatalog', 'Helix', 'jclouds', 'JSPWiki', 'Marmotta', 'Mesos', 'Onami', 'Openmeetings'], 'retired': ['Provisionr']}, '2014': {'new': ['Brooklyn', 'Calcite', 'Corinthia', 'DataFu', 'Flink', 'HTrace', 'Ignite', 'Johnzon', 'Kylin', 'Lens', 'NiFi', 'Parquet', 'Ranger', 'REEF', 'SAMOA', 'Slider', 'Tamaya', 'Taverna', 'Zeppelin'], 'graduated': ['Allura', 'Celix', 'DeviceMap', 'Drill', 'Falcon', 'Flink', 'Knox', 'MetaModel', 'Olingo', 'Open Climate Workbench', 'Phoenix', 'Spark', 'Storm', 'Stratos', 'Tajo', 'Tez', 'VXQuery'], 'retired': ['Hadoop Development Tools (HDT)', 'S4']}, '2015': {'new': ['Apex', 'AsterixDB', 'Atlas', 'Climate Model Diagnostic Analyzer', 'Concerted', 'CommonsRDF', 'Cotton', 'Eagle', 'Fineract', 'FreeMarker', 'Geode', 'Groovy', 'HAWQ', 'HORN', 'Impala', 'Kudu', 'MADlib', 'Metron', 'Milagro', 'Mynewt', 'Myriad', 'OpenAz', 'Rya', 'S2Graph', 'SINGA', 'SystemML', 'TinkerPop', 'Toree', 'Trafodion', 'Unomi'], 'graduated': ['Aurora', 'Brooklyn', 'Calcite', 'Groovy', 'Ignite', 'Kylin', 'Lens', 'NiFi', 'Parquet', 'REEF', 'Samza', 'Usergrid'], 'retired': ['Corinthia', 'Cotton', 'Droids', 'Kalumet', 'NPanday', 'Ripple']}, '2016': {'new': ['Airflow', 'Annotator', 'AriaTosca', 'Beam', 'CarbonData', 'DistributedLog', 'Edgent', 'Flagon', 'Fluo', 'Gearpump', 'Gossip', 'Griffin', 'Guacamole', 'Hivemall', 'iota', 'Joshua', 'Juneau', 'Mnemonic', 'NetBeans', 'Omid', 'OpenWhisk', 'Pirk', 'Pony Mail', 'PredictionIO', 'Quickstep', 'RocketMQ', 'Spot', 'Tephra', 'Traffic Control', 'Weex'], 'graduated': ['Apex', 'AsterixDB', 'Beam', 'CommonsRDF', 'Eagle', 'Geode', 'Johnzon', 'Kudu', 'Sentry', 'TinkerPop', 'Twill', 'Zeppelin'], 'retired': ['Concerted', 'OpenAz']}, '2017': {'new': ['Amaterasu', 'Crail', 'Daffodil', 'Gobblin', 'Heron', 'Livy', 'MXNet', 'PageSpeed', 'PLC4X', 'Pulsar', 'Ratis', 'SDAP', 'ServiceComb', 'SkyWalking', 'Superset'], 'graduated': ['Atlas', 'CarbonData', 'DistributedLog', 'Fineract', 'Fluo', 'Guacamole', 'Impala', 'Juneau', 'log4cxx2', 'MADlib', 'Metron', 'Mnemonic', 'Mynewt', 'PredictionIO', 'Ranger', 'RocketMQ', 'Streams', 'SystemML', 'Trafodion'], 'retired': ['Blur', 'Climate Model Diagnostic Analyzer', 'HORN', 'MRQL', 'Pirk', 'Sirona']}, '2018': {'new': ['brpc', 'DataLab', 'Doris', 'Druid', 'Dubbo', 'ECharts', 'Iceberg', 'IoTDB', 'Marvin-AI', 'Nemo', 'Pinot', 'ShardingSphere', 'Warble', 'Zipkin'], 'graduated': ['Airflow', 'DataFu', 'FreeMarker', 'Griffin', 'HAWQ', 'Joshua', 'Pulsar', 'ServiceComb', 'Traffic Control'], 'retired': ['AriaTosca', 'Gearpump', 'Gossip', 'HTrace', 'iota', 'ODF Toolkit', 'Quickstep', 'Slider', 'Wave']}, '2019': {'new': ['APISIX', 'DataSketches', 'DolphinScheduler', 'Hudi', 'Teaclave', 'NuttX', 'StreamPipes', 'Training', 'InLong', 'Tuweni', 'TVM'], 'graduated': ['BatchEE', 'Druid', 'Dubbo', 'NetBeans', 'Omid', 'OpenWhisk', 'PLC4X', 'Rya', 'SINGA', 'SkyWalking', 'Tephra', 'Unomi'], 'retired': ['Amaterasu', 'Edgent', 'Zipkin']}, '2020': {'new': ['AGE', 'BlueMarlin', 'Hop', 'Liminal', 'NLPCraft', 'Pegasus', 'Sedona', 'Wayang', 'YuniKorn'], 'graduated': ['APISIX', 'DataSketches', 'ECharts', 'Hudi', 'Iceberg', 'IoTDB', 'ShardingSphere', 'Superset', 'TVM'], 'retired': ['Myriad', 'S2Graph', 'Tamaya', 'Taverna', 'Warble']}, '2021': {'new': ['EventMesh', 'Kyuubi', 'Linkis', 'SeaTunnel', 'ShenYu'], 'graduated': ['Daffodil', 'DolphinScheduler', 'Gobblin', 'Hop', 'Pinot', 'Ratis'], 'retired': ['SAMOA', 'Weex']}, '2022': {'new': ['DevLake', 'HugeGraph', 'Kvrocks', 'Uniffle'], 'graduated': ['AGE', 'Doris', 'InLong', 'YuniKorn'], 'retired': ['BlueMarlin', 'Crail']}}}\n"
     ]
    }
   ],
   "source": [
    "def getCurrent(year,raw_df):\n",
    "    df = raw_df[(raw_df['startmonth'].dt.year == int(year))]\n",
    "    return list(df['name'])\n",
    "\n",
    "def getGraduated(year,raw_df):\n",
    "    df = raw_df[(raw_df['status'] == 'graduated') & (raw_df['endmonth'].dt.year == int(year))]\n",
    "    return list(df['name'])\n",
    "\n",
    "def getRetired(year,raw_df):\n",
    "    df = raw_df[(raw_df['status'] == 'retired') & (raw_df['endmonth'].dt.year == int(year))]\n",
    "    return list(df['name'])\n",
    "\n",
    "\n",
    "def BarData_YEAR():\n",
    "    BarData={}\n",
    "    BarData['yearList'] = Podlings_yearList\n",
    "    BarData['new'] =[]\n",
    "    BarData['graduated'] = []\n",
    "    BarData['retired'] = []\n",
    "    BarData['status'] = {}\n",
    "    for year in Podlings_yearList:\n",
    "        current = getCurrent(year,podlings_status_info)\n",
    "        graduated = getGraduated(year,podlings_status_info)\n",
    "        retired = getRetired(year,podlings_status_info)\n",
    "        BarData['new'].append(len(current))\n",
    "        BarData['graduated'].append(-len(graduated))\n",
    "        BarData['retired'].append(-len(retired))\n",
    "        BarData['status'][year]={\n",
    "            'new':current,\n",
    "            'graduated':graduated,\n",
    "            'retired':retired\n",
    "        }\n",
    "\n",
    "\n",
    "    return BarData\n",
    "\n",
    "BarData_YEAR = BarData_YEAR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "store the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "committer_dic = {\n",
    "    'scatter':scatter,\n",
    "    'boxplot': boxplot,\n",
    "    'bar':bar,\n",
    "    \"committee_detail\":committee_detail_dict,\n",
    "    \"BarData_YEAR\":BarData_YEAR\n",
    "}\n",
    "\n",
    "file_name = 'committer.json'\n",
    "\n",
    "with open(file_name,'w') as file_obj:\n",
    "    json.dump(committer_dic,file_obj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "429c4da532d5a49305ad374da5bd9411413fc9c5f93bdb5e51c34bc796003ebd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
